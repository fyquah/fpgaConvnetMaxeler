import java.util.ArrayList;
import java.util.List;

import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Stream.OffsetExpr;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;

/* 
 * io.input:
 *  x : DFEVector[inputChannels] 
 * io.output:
 *  - y0, y1, y2, ...., y{ff - 1}
 *  - w0, w1, w2, ...., w{ff - 1}
 *  Bias will be handled at a later stage of the pipeline.
 *  where y_i and p_i are both inputs to ConvolutionUnit_i
 *        and are of type DFEVector[kff]
 *        (No point streaming other things at this point, as it wastes resources
 *         and increases multiplexing complexity at ConvolutionUnit).
 *        (ConvolutionUnit can do at most kff multiplications simultaneously
 *         anyway, this moves the complexity of scheduling to the place it belongs
 *         i.e: here)
 *        (they are both sliding windows of the input streams
 *         and the convolution parameters respectively.)
 */

public class ConvolutionSchedulerKernel extends ConvolutionKernelBase {
    private final DFEVectorType<DFEVar> inputVectorType, outputVectorType;
    private final SlidingWindow[] slidingWindows;
    private final DFEVector<DFEVar> input;
    private final List<DFEVector<DFEVar>> output_w, output_y;
    private final Dimension inputDimension;
    private final int foldingFactor, kernelFoldingFactor, kernelDim;
    private final DFEVar row, col, iter, loopIter, convIter;
    private final List<List<float[][]>> convolutionWeights;
    private final CounterChain masterChain;

    public ConvolutionSchedulerKernel(
           KernelParameters kp,
           ConvolutionParameters params) {
        super(kp, params);

        inputDimension = params.inputDim;
        kernelDim = params.kernelDim;
        foldingFactor = params.foldingFactor;
        kernelFoldingFactor = params.kernelFoldingFactor;
        convolutionWeights = params.getKernels();
        masterChain = control.count.makeCounterChain();
        inputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType,
                inputDimension.channels());
        outputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType,
                kernelFoldingFactor);
        input = inputVectorType.newInstance(this);
        output_w = new ArrayList<DFEVector<DFEVar>>();
        output_y = new ArrayList<DFEVector<DFEVar>>();;
        slidingWindows = new SlidingWindow[inputDimension.channels()];

        for (int i = 0 ; i < foldingFactor; i++) {
            output_w.add(outputVectorType.newInstance(this));
            output_y.add(outputVectorType.newInstance(this));
        }

        row = Utils.chainCounterOrZero(
                this, masterChain, inputDimension.height());
        col = Utils.chainCounterOrZero(
                this, masterChain, inputDimension.width());
        loopIter = Utils.chainCounterOrZero(
                this, masterChain, getLoopIterations());
        convIter = Utils.chainCounterOrZero(
                this, masterChain, getConvLoopIterations());
        iter = control.count.simpleCounter(
                Utils.ceilLog2(getLoopIterations() * getConvLoopIterations()),
                getLoopIterations() * getConvLoopIterations());

        initSlidingWindow();
        initOutputs();

        // TODO(fyq14): Optimize border cases
        DFEVar outputControlFlag = ~isBorder();
        DFEVar inputControlFlag = loopIter.eq(0) & convIter.eq(0);

        input <== io.input(getInputName(), inputVectorType, inputControlFlag);

        for (int i = 0 ; i < foldingFactor ; i++) {
            io.output(getWeightOutputName(i), output_w[i], outputVectorType, outputControlFlag);
            io.output(getPixelOutputName(i), output_y[i], outputVectorType, outputControlFlag);
            io.forceOutputsTogether(getWeightOutputName(i), getPixelOutputName(i));
        }
    }

    /* Right now, this is not pipelined, so cyclesPerImage does not take any extra args */
    public int cyclesPerImage() {
        return (inputDimension.width()
                * inputDimension.height()
                * getLoopIterations()
                * getConvLoopIterations());
    }

    public String getInputName() {
        return "input";
    }

    public String getWeightOutputName(int convUnitId) {
        return "output_w_" + convUnitId;
    }

    public String getPixelOutputName(int convUnitId) {
        return "output_x_" + convUnitId;
    }

    /*
     * This is not used, but as the base class is a ConvolutionKernelBase
     * we will need to implement this.
     */
    public String getOffsetExprName() {
        return "";
    }

    protected DFEVar isBorder() {
        DFEVar flag = constant.var(dfeBool(), 0);
        for (int i = 0 ; i < (kernelDim - 1) / 2 ; i++) {
            flag = flag | row.eq(i) | col.eq(i)
                | row.eq(inputDimension.height() - 1 - i)
                | col.eq(inputDimension.width() - 1 - i);
        }

        return flag;
    }

    private void initSlidingWindow() {
        for (int i = 0 ; i < inputDimension.channels() ; i++) {
            slidingWindows[i] = new SlidingWindow(
                this,
                input[i],
                inputDimension.height(),
                inputDimension.width(),
                kernelDim,
                new OffsetExpr(getLoopIterations() * getConvLoopIterations()));
        }
    }

    private void initOutputs() {
        for (int i = 0 ; i < foldingFactor ; i++) {
            List<ConvChannelIndex> indices = getConvUnitChannelIndices(i);
            DFEVector<DFEVar> convWeights = toMuxedWeight(iter, indices);
            DFEVector<DFEVar> convInputs = toMuxedPixel(iter, indices);
            output_w[i] <== convWeights;
            output_y[i] <== convInputs;
        }
    }

    protected DFEVector<DFEVar> zeroVector(DFEVectorType<DFEVar> type) {
        DFEVector<DFEVar> newVector = type.newInstance(this);

        for (int i = 0 ; i < newVector.getSize() ; i++) {
            newVector[i] <== constant.var(GlobalConfig.dataType, 0);
        }

        return newVector;
    }

    protected DFEVector<DFEVar> toMuxedPixel(
            DFEVar iter,  /* A counter from 0...convIter * loopIter */
            List<ConvChannelIndex> indices) {

        DFEVector<DFEVar> output = outputVectorType.newInstance(this);

        for (int multiplierId = 0 ; multiplierId < kernelFoldingFactor ; multiplierId++) {
            final List<DFEVar>choices = new ArrayList<DFEVar>();
            final int totalSize = getLoopIterations() * getConvLoopIterations();

            for (int idx = 0 ; idx < indices.size() ; idx++) {

                // we don't care about the outputChannel here.
                int inputChannel = indices[idx].in;

                /* Looping through the number of iterations we want to spend on
                 * multipler {multiplierId}. We spend getConvLoopIterations() here
                 * per convolution for each multiplier. */
                for (int i = 0; i < getConvLoopIterations() ; i++) {
                    int y = multiplierId + i * kernelFoldingFactor;

                    if (y < kernelDim * kernelDim) {
                        choices.add(slidingWindows[inputChannel].output[y]);
                    } else {
                        choices.add(constant.var(GlobalConfig.dataType, 0.0));
                    }
                }
            }

            Utils.assertTrue(totalSize == choices.size());
            output[multiplierId] <== control.mux(
                    iter,
                    choices.toArray(new DFEVar[choices.size()]));
        }

        return output;
    }

    protected DFEVector<DFEVar> toMuxedWeight(
            DFEVar iter,  /* A counter from 0 to (loops * convLoops) - 1 */
            List<ConvChannelIndex> indices) {
        DFEVector<DFEVar> output = outputVectorType.newInstance(this);

        for (int multiplierId = 0 ; multiplierId < kernelFoldingFactor ; multiplierId++) {
            final int totalSize = getLoopIterations() * getConvLoopIterations();
            Memory<DFEVar> table = mem.alloc(GlobalConfig.dataType, totalSize);
            double[] data = new double[totalSize];

            for (int idx = 0 ; idx < indices.size() ; idx++) {
                /* We want to spend getConvLoopIterations() on each index */

                int outputChannel = indices[idx].out;
                int inputChannel = indices[idx].in;

                /* Looping through the number of iterations we want to spend on
                 * multipler {multiplierId}. We spend getConvLoopIterations() here
                 * per convolution for each multiplier. */
                for (int i = 0; i < getConvLoopIterations() ; i++) {
                    int y = multiplierId + i * kernelFoldingFactor;
                    int x = idx * getConvLoopIterations() + i;
                    float[][] weights = convolutionWeights[outputChannel][inputChannel];

                    if (y < kernelDim * kernelDim) {
                        data[x] = weights[y / kernelDim][y % kernelDim];
                    } else {
                        data[x] = 0.0;
                    }
                }
            }

            table.setContents(data);
            output[multiplierId] <== table.read(iter);
        }

        return output;
    }
}
