package fpgaconvnet;

import java.lang.RuntimeException;

import java.util.List;
import java.util.ArrayList;

import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Count;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Count.Counter;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Stream.OffsetExpr;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;

import fpgaconvnet.protos.Parameters.LayerParameter;


public class ConvolutionAccumulatorKernel extends ConvolutionKernelBase {
    private final List<Memory<DFEVar>> biasRoms;
    private final LayerParameter layerParams;
    private final DFEVectorType<DFEVar> inputVectorType;
    private final DFEVectorType<DFEVar> outputVectorType;

    private List<DFEVar> map(List<DFEVector<DFEVar>> list, int index) {
        /* Gets the index-th element of every vector in list. */
        List<DFEVar> ret = new ArrayList<DFEVar>();
        for (DFEVector<DFEVar> vector: list) {
            ret.add(vector[index]);
        }
        return ret;
    }

    private DFEVar relu(DFEVar x) {
        return (x > 0 ? x : 0);
    }

    public ConvolutionAccumulatorKernel(KernelParameters kp, LayerParameter params) {
        super(kp, params);

        layerParams = params;
        inputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType, layerParams.getConv().getConvFoldingFactor());
        outputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType, layerParams.getNumOutputs());
        biasRoms = new ArrayList<Memory<DFEVar>>();

        for (int i = 0; i < params.getNumOutputs() ; i++) {
            biasRoms.add(mem.alloc(GlobalConfig.dataType, 2));
        }

        DFEVector<DFEVar> output = outputVectorType.newInstance(this);
        List<DFEVector<DFEVar>> inputVectors = new ArrayList<DFEVector<DFEVar>>();

        // Counters for initialization
        DFEVar initChannel = control.count.simpleCounter(
                Utils.ceilLog2(initCycles()),
                initCycles());
        Counter initializationCompleteCtr = control.count.makeCounter(
                control.count.makeParams(1)
                .withInc(1)
                .withMax(1)
                .withWrapMode(Count.WrapMode.STOP_AT_MAX)
                .withEnable(initChannel.eq(initCycles() - 1)));

        DFEVar initWeightsFlag = io.scalarInput("init", dfeUInt(1));
        DFEVar initializationComplete = initializationCompleteCtr.getCount();
        DFEVar isInitializingWeights = initWeightsFlag & ~initializationComplete;

        // Runtime Counters and loop variables
        OffsetExpr loopOffsetExpr = stream.makeOffsetAutoLoop(getOffsetExprName());
        DFEVar pipelineLengthVar = loopOffsetExpr.getDFEVar(this,dfeUInt(32));
        CounterChain chain = control.count.makeCounterChain(~isInitializingWeights);
        DFEVar schedulerIter = Utils.chainCounterOrZero(this, chain, getSchedulerIterations());
        DFEVar convIter = Utils.chainCounterOrZero(this, chain, getConvolutionIterations());
        DFEVar kernelIter = Utils.chainCounterOrZero(this, chain, getKernelIterations());
        DFEVar pipelineStage = chain.addCounter(pipelineLengthVar, 1);
        DFEVar streamCounter = control.count.simpleCounter(
                32,
                getKernelIterations() * getConvolutionIterations() * getSchedulerIterations());

        // Kernel IO interfaces
        DFEVar rawBiasInput = io.input(getBiasInputName(),
                                       GlobalConfig.cpuType,
                                       isInitializingWeights);
        DFEVar biasInput = rawBiasInput.cast(GlobalConfig.dataType);
        DFEVar inputControlFlag = ~isInitializingWeights;
        DFEVar outputControlFlag =
                ~isInitializingWeights
                & schedulerIter.eq(getSchedulerIterations() - 1)
                & convIter.eq(getConvolutionIterations() - 1)
                & kernelIter.eq(getKernelIterations() - 1);

        for (int i = 0 ; i < layerParams.getConv().getWorkerFactor() ; i++) {
            inputVectors.add(io.input(getInputName(i), inputVectorType, inputControlFlag));
        }
        if (layerParams.getIsLastLayer()) {
            /* Last layer - cast from fixed point to dfe float. */
            DFEVectorType<DFEVar> rawOutputVectorType = new DFEVectorType<DFEVar>(
                    GlobalConfig.cpuType, layerParams.getNumOutputs());
            DFEVector<DFEVar> rawOutput = rawOutputVectorType.newInstance(this);

            for (int i = 0 ; i < layerParams.getNumOutputs() ; i++) {
                rawOutput[i] <== output[i].cast(GlobalConfig.cpuType);
            }
            io.output(getOutputName(), rawOutput, rawOutputVectorType, outputControlFlag);

        } else {
            io.output(getOutputName(), output, outputVectorType, outputControlFlag);
        }

        // logic for initializing weights
        debug.simPrintf(
                isInitializingWeights & (initChannel < params.getNumOutputs()),
                "AccumulatorInit | layer %d | Writing %.3f to %d\n",
                params.getLayerId(),
                biasInput,
                initChannel.cast(dfeUInt(Utils.ceilLog2(params.getNumOutputs()))));
        for (int i = 0 ; i < params.getNumOutputs() ; i++) {
            biasRoms[i].write(
                    constant.var(dfeUInt(1), 0),
                    biasInput,
                    isInitializingWeights & (initChannel.eq(i)));
        }

        // logic for accumulating outputs
        for (int channel = 0 ; channel < layerParams.getNumOutputs() ; channel++) {
            final int convFoldingFactor = layerParams.getConv().getConvFoldingFactor();
            DFEVar acc = GlobalConfig.dataType.newInstance(this);
            DFEVar initFlag = streamCounter.eq(
                    (channel / layerParams.getConv().getConvFoldingFactor()));
            DFEVar sumVars = Utils.treeReduceAdd(map(inputVectors, channel % convFoldingFactor));
            DFEVar channelOutputFlag = (
                    convIter.eq(channel / layerParams.getConv().getConvFoldingFactor()));
            DFEVar muxedSumVars = channelOutputFlag ? sumVars : 0.0;
            DFEVar bias = biasRoms[channel].read(constant.var(dfeUInt(1), 0));
            DFEVar carriedSum = stream.offset(acc, -loopOffsetExpr);

            // push and pop pipelining factor required to make sure this accumulator runs at
            // 0-tick latency (i.e: stream.offset(-1) works)
            optimization.pushPipeliningFactor(0);
            DFEVar prevAcc = initFlag ? bias : carriedSum;
            optimization.popPipeliningFactor();

            acc <== muxedSumVars + prevAcc;

            if (layerParams.getActivation() == LayerParameter.Activation.None) {
                output[channel] <== acc;

            } else if (layerParams.getActivation() == LayerParameter.Activation.Relu) {
                output[channel] <== relu(acc);

            } else {
                throw new RuntimeException("Unsupported activation type");
            }
        }

        // debugging output
        // String s_output = "[";
        // String s_conv = "[\n";
        // List<Object> debugValues = new ArrayList<Object>();
        // debugValues.add((Integer) layerParams.getLayerId());
        // debugValues.add(outputControlFlag);
        // debugValues.add(pipelineStage);
        // debugValues.add(pipelineLengthVar);
        // debugValues.add(schedulerIter);
        // debugValues.add(convIter);
        // debugValues.add(kernelIter);
        // for (DFEVector<DFEVar> vector: inputVectors) {
        //     s_conv += "[";
        //     for (int i = 0 ; i < params.getConv().getConvFoldingFactor() ; i++) {
        //         debugValues.add(vector[i]);
        //         s_conv += "%.3f, ";
        //     }
        //     s_conv += "]\n";
        // }
        // for (int i = 0 ; i < params.getNumOutputs() ; i++) {
        //     debugValues.add(output[i]);
        //     s_output += "%.3f, ";
        // }
        // s_conv += "]";
        // s_output += "]";
        // debug.simPrintf(
        //         "ConvolutionAccumulatorKernel[layer = %d]"
        //         + " outputControlFlag = %d"
        //         + " pipelineStage = %d pipelineLengthVar = %d"
        //         + " schedulerIter = %d convIter = %d kernelIter = %d"
        //         + "\ninputs = " + s_conv + "\n"
        //         + "\noutput = " + s_output + "\n",
        //         debugValues.toArray(new Object [1]));
    }

    public String getBiasInputName() {
        return "input_bias";
    }

    public String getInputName(int workerId) {
        return "input_" + workerId;
    }

    public String getOutputName() {
        return "output";
    }

    public String getOffsetExprName() {
        return String.format("offset");
    }

    public int initCycles() {
        // maxeler requires streams to be a multiple of 16 bytes = 4 * 4 bytes.
        return Utils.divCeil(layerParams.getNumOutputs(), 4) * 4;
    }

    public int cyclesPerImage() {
        int totalOutputPixels = layerParams.getOutputHeight() * layerParams.getOutputWidth();
        int cyclesPerPixel = getSchedulerIterations()
                * getConvolutionIterations()
                * getKernelIterations();
        return totalOutputPixels * cyclesPerPixel;
    }
}
