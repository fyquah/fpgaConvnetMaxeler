package fpgaconvnet;

import java.util.List;
import java.util.ArrayList;

import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Stream.OffsetExpr;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.managers.engine_interfaces.InterfaceParam;

import fpgaconvnet.protos.Parameters.LayerParameter;


public class ConvolutionAccumulatorKernel extends ConvolutionKernelBase {
    private final Memory<DFEVar> biasRom;
    private final LayerParameter layerParams;
    private final DFEVectorType<DFEVar> inputVectorType;
    private final DFEVectorType<DFEVar> outputVectorType;

    private List<DFEVar> map(List<DFEVector<DFEVar>> list, int index) {
        /* Gets the index-th element of every vector in list. */
        List<DFEVar> ret = new ArrayList<DFEVar>();
        for (DFEVector<DFEVar> vector: list) {
            ret.add(vector[index]);
        }
        return ret;
    }

    private DFEVar relu(DFEVar x) {
        return (x > 0 ? x : 0);
    }

    public ConvolutionAccumulatorKernel(KernelParameters kp, LayerParameter params) {
        super(kp, params);

        layerParams = params;
        inputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType, layerParams.getConv().getConvFoldingFactor());
        outputVectorType = new DFEVectorType<DFEVar>(
                GlobalConfig.dataType, layerParams.getNumOutputs());
        biasRom = mem.alloc(GlobalConfig.dataType, params.getNumOutputs());
        biasRom.mapToCPU(String.format("bias_layer_%d", params.getLayerId()));

        DFEVector<DFEVar> output = outputVectorType.newInstance(this);
        DFEVar inputControlFlag = dfeUInt(1).newInstance(this);
        DFEVar outputControlFlag = dfeUInt(1).newInstance(this);
        List<DFEVector<DFEVar>> inputVectors = new ArrayList<DFEVector<DFEVar>>();
        for (int i = 0 ; i < layerParams.getConv().getWorkerFactor() ; i++) {
            inputVectors.add(io.input(getInputName(i), inputVectorType, inputControlFlag));
        }
        io.output(getOutputName(), output, outputVectorType, outputControlFlag);

        OffsetExpr loopOffsetExpr = stream.makeOffsetAutoLoop(getOffsetExprName());
        DFEVar pipelineLengthVar = loopOffsetExpr.getDFEVar(this,dfeUInt(32));
        CounterChain chain = control.count.makeCounterChain();
        DFEVar schedulerIter = Utils.chainCounterOrZero(this, chain, getSchedulerIterations());
        DFEVar convIter = Utils.chainCounterOrZero(this, chain, getConvolutionIterations());
        DFEVar kernelIter = Utils.chainCounterOrZero(this, chain, getKernelIterations());
        DFEVar pipelineStage = chain.addCounter(pipelineLengthVar, 1);

        inputControlFlag <== pipelineStage.eq(0);
        outputControlFlag <==
                schedulerIter.eq(getSchedulerIterations() - 1)
                & convIter.eq(getConvolutionIterations() - 1)
                & kernelIter.eq(getKernelIterations() - 1)
                & pipelineStage.eq(pipelineLengthVar - 1);

        for (int channel = 0 ; channel < layerParams.getNumOutputs() ; channel++) {
            final int convFoldingFactor = layerParams.getConv().getConvFoldingFactor();
            DFEType addressType = dfeUInt(Utils.ceilLog2(layerParams.getNumOutputs()));
            DFEVar flag = (schedulerIter.eq(0)
                    & convIter.eq(channel / layerParams.getConv().getConvFoldingFactor())
                    & kernelIter.eq(0)
                    & pipelineStage.eq(0));
            DFEVar prevOutput = (
                    flag ? biasRom.read(constant.var(addressType, channel))
                    : stream.offset(output[channel], -loopOffsetExpr));
            DFEVar sumVars = Utils.treeReduceAdd(map(inputVectors, channel % convFoldingFactor));
            DFEVar channelOutputFlag = (
                    convIter.eq(channel / layerParams.getConv().getConvFoldingFactor())
                    & kernelIter.eq(0)
                    & pipelineStage.eq(0));
            DFEVar acc = (
                    channelOutputFlag ? (prevOutput + sumVars) : prevOutput);
            output[channel] <== outputControlFlag ? relu(acc) : acc;
        }

        // debugging output
        String s_output = "[";
        String s_conv = "[\n";
        List<Object> debugValues = new ArrayList<Object>();
        debugValues.add((Integer) layerParams.getLayerId());
        debugValues.add(inputControlFlag);
        debugValues.add(outputControlFlag);
        debugValues.add(pipelineStage);
        debugValues.add(pipelineLengthVar);
        debugValues.add(schedulerIter);
        debugValues.add(convIter);
        debugValues.add(kernelIter);
        for (DFEVector<DFEVar> vector: inputVectors) {
            s_conv += "[";
            for (int i = 0 ; i < params.getConv().getConvFoldingFactor() ; i++) {
                debugValues.add(vector[i]);
                s_conv += "%.3f, ";
            }
            s_conv += "]\n";
        }
        for (int i = 0 ; i < params.getNumOutputs() ; i++) {
            debugValues.add(output[i]);
            s_output += "%.3f, ";
        }
        s_conv += "]";
        s_output += "]";
        debug.simPrintf(
                "ConvolutionAccumulatorKernel[layer = %d]"
                + " inputControlFlag = %d outputControlFlag = %d"
                + " pipelineStage = %d pipelineLengthVar = %d"
                + " schedulerIter = %d convIter = %d kernelIter = %d"
                + "\ninputs = " + s_conv + "\n"
                + "\noutput = " + s_output + "\n",
                debugValues.toArray(new Object [1]));

        // // Pipelined adder - may or may not be better, but this probably will not
        //                      be the bottle neck of the performance, so there is not much point
        //                      pouring too much work into this.
        // DFEParLoop loop = new DFEParLoop(this, "loop");
        // List<DFEVar> inputVars = new ArrayList<DFEVar>();
        // List<DFEVar> transposedInputVars = new ArrayList<DFEVar>();
        // for (int i = 0 ; i < layerParams.getConv().getWorkerFactor() ; i++) {
        //     DFEVar input = io.input(getInputName(i), GlobalConfig.dataType, loop.ndone);
        //     inputVars.add(input);
        //     transposedInputVars.add(transpose(input, abc, loop.pipeline_len));
        // }
        // loop.set_input(biasRom.read(address));

        // DFEVar result = loop.feedback + Utils.treeReduceAdd(transposedInputVars);
        // loop.set_output(result);
        // io.output("result", result, GlobalConfig.dataType, loop.done);
    }

    public String getInputName(int workerId) {
        return "input_" + workerId;
    }

    public String getOutputName() {
        return "output";
    }

    public String getOffsetExprName() {
        return String.format("offset");
    }

    public int cyclesPerImage() {
        int totalOutputPixels = layerParams.getOutputHeight() * layerParams.getOutputWidth();
        int cyclesPerPixel = getSchedulerIterations()
                * getConvolutionIterations()
                * getKernelIterations();
        return totalOutputPixels * cyclesPerPixel;
    }
}
