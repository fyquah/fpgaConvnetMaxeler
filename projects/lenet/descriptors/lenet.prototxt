layer {
    input_height: 28
    input_width: 28
    num_inputs: 1
    num_outputs: 20

    conv: {
        worker_factor: 1
        conv_folding_factor: 10
        kernel_folding_factor: 13
        bram_factor: 20
        look_ahead: 2

        kernel_size: 5
    }

    activation: Relu
}
# layer {
#     pool: {
#         type: Max
#         dim: 2
#         channel_folding_factor: 10
#     }
# }
# layer {
#     input_height: 12
#     input_width: 12
#     num_inputs: 20
#     num_outputs: 50
#     output_height: 8
#     output_width: 8
# 
#     conv: {
#         worker_factor: 7
#         conv_folding_factor: 25
#         kernel_folding_factor: 7
#         bram_factor: 350
#         look_ahead: 2
# 
#         kernel_size: 5
#     }
# 
#     activation: Relu
# }
# layer {
#     pool: {
#         type: Max
#         dim: 2
#         channel_folding_factor: 5
#     }
# }
