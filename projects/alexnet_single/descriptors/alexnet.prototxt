num_fpga_available: 1
allow_runtime_reconfiguration: true

layer {
    input_height: 227
    input_width: 227
    num_inputs: 3

    num_outputs: 96

    conv: {
        kernel_size: 11
        stride: 4
    }

    activation: Relu
}
layer {
    lrn {
        local_size: 5
        alpha: 0.0001
        beta: 0.75
    }
}
layer {
    pool: {
        type: Max
        dim: 3
        stride: 2
    }
}
layer {
    num_outputs: 256

    conv {
        pad: 2
        kernel_size: 5
        group: 2
    }

    activation: Relu
}
layer {
    lrn {
        local_size: 5
        alpha: 0.0001
        beta: 0.75
    }
}
layer {
    pool {
        dim: 3
        stride: 2
        type: Max
    }
}
layer {
    num_outputs: 384

    conv {
        pad: 1
        kernel_size: 3
    }

    activation: Relu
}
layer {
    num_outputs: 384

    conv {
        pad: 1
        kernel_size: 3
        group: 2
    }

    activation: Relu
}
layer {
    num_outputs: 256

    conv {
        pad: 1
        kernel_size: 3
        group: 2
    }

    activation: Relu
}
layer {
    pool {
        dim: 3
        stride: 2
        type: Max
    }
} 
