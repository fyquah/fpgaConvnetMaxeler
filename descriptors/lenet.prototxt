layer {
    input_height: 12
    input_width: 12
    num_inputs: 20
    num_outputs: 50
    output_height: 8
    output_width: 8

    conv: {
        worker_factor: 5
        conv_folding_factor: 17
        kernel_folding_factor: 5

        kernel_size: 5
        activation: Relu
    }
}
